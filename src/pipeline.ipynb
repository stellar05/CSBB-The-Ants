{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa13fd1",
   "metadata": {},
   "source": [
    "## Lymph Node Metastasis Detection Pipeline\n",
    "\n",
    "Welcome to the notebook for The Ants machine learning pipeline. This notebook contains a simple machine learning model trained using images from the [PCam](https://github.com/basveeling/pcam) dataset. This model was used to extract areas of interest to image from patient lymph node slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as T    \n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f096258",
   "metadata": {},
   "source": [
    "## Custom H5 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89d9a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class H5PatchDataset(Dataset):\n",
    "    \"\"\"Reads images/labels from an .h5 file. Assumes datasets 'x' and 'y' exist.\n",
    "    x: (N, H, W, C) uint8\n",
    "    y: (N,) int labels 0/1\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, h5_path_x, h5_path_y, transform=None, img_key=\"x\", label_key=\"y\"):\n",
    "        self.h5_path_x = h5_path_x\n",
    "        self.h5_path_y = h5_path_y\n",
    "        self.transform = transform\n",
    "        self.img_key = img_key\n",
    "        self.label_key = label_key\n",
    "\n",
    "        self._h5_img = None\n",
    "        self._h5_label = None\n",
    "        self._length = None\n",
    "\n",
    "    def __len__(self):\n",
    "        if self._length is not None:\n",
    "            return int(self._length)\n",
    "        with h5py.File(self.h5_path_y, \"r\") as fl:\n",
    "            return int(fl[self.label_key].shape[0])\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if self._h5_img is None:\n",
    "            self._h5_img = h5py.File(self.h5_path_x, \"r\")\n",
    "            self._h5_label = h5py.File(self.h5_path_y, \"r\")\n",
    "            self._length = int(self._h5_label[self.label_key].shape[0])\n",
    "\n",
    "        try:\n",
    "            img = self._h5_img[self.img_key][idx]\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\n",
    "                f\"Failed reading image index {idx} with key '{self.img_key}'\"\n",
    "            ) from e\n",
    "        try:\n",
    "            label = int(self._h5_label[self.label_key][idx])\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\n",
    "                f\"Failed reading label index {idx} with key '{self.label_key}'\"\n",
    "            ) from e\n",
    "\n",
    "        if not isinstance(img, np.ndarray):\n",
    "            img = np.array(img)\n",
    "\n",
    "        pil = Image.fromarray(img.astype(\"uint8\"))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img_tensor = self.transform(pil)\n",
    "        else:\n",
    "            img_tensor = T.ToTensor()(pil)\n",
    "\n",
    "        return img_tensor, torch.tensor(label, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c208eb",
   "metadata": {},
   "source": [
    "## Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db309e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_features):\n",
    "        super(CNN, self).__init__()\n",
    "        # 96 x 96\n",
    "        self.conv1 = nn.Conv2d(in_channels, hidden_channels[0], kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_channels[0])\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.max_pool1 = nn.AvgPool2d(2)\n",
    "        # 48 x 48\n",
    "        self.conv2 = nn.Conv2d(hidden_channels[0], hidden_channels[1], kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_channels[0])\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.max_pool2 = nn.AvgPool2d(2)\n",
    "        # 24 x 24\n",
    "        self.conv3 = nn.Conv2d(hidden_channels[1], hidden_channels[2], kernel_size=5, padding=2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.max_pool3 = nn.AvgPool2d(2)\n",
    "        # 12 x 12\n",
    "        self.fc1 = nn.Linear(12*12*hidden_channels[2], 12*12)\n",
    "        self.fc = nn.Linear(144, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.max_pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.max_pool3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1912e24",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae4a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(img_size=96, train=True):\n",
    "    if train:\n",
    "        return T.Compose(\n",
    "            [\n",
    "                T.Resize((img_size, img_size)),\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.RandomVerticalFlip(),\n",
    "                T.RandomRotation(90),\n",
    "                T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        return T.Compose(\n",
    "            [\n",
    "                T.Resize((img_size, img_size)),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "def eval_accuracy(data_loader, cnn, device=torch.device('cpu')):\n",
    "    cnn.eval()\n",
    "\n",
    "    accuracy = 0\n",
    "    n = 0\n",
    "\n",
    "    for X, y in tqdm(data_loader):\n",
    "        X, y = X.to(device), y.to(device).long()\n",
    "        with torch.no_grad():\n",
    "            preds = ((cnn(X).squeeze(1))>0).long()\n",
    "            accuracy += (preds == y).sum().item()\n",
    "            n += y.size(0)\n",
    "    \n",
    "    return accuracy/n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f66bba",
   "metadata": {},
   "source": [
    "## Model Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffce544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args\n",
    "h5_img = \"data\\\\camelyonpatch_split_training_x.h5\"\n",
    "h5_label = \"data\\\\camelyonpatch_split_training_y.h5\"\n",
    "in_channels = 3\n",
    "hidden_channels = [64, 64, 64]\n",
    "out_features = 1\n",
    "epochs = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "transform_train = get_transforms()\n",
    "transform_test = get_transforms(train=False)\n",
    "\n",
    "train_data = H5PatchDataset(\n",
    "        h5_path_x=h5_img,\n",
    "        h5_path_y=h5_label,\n",
    "        transform=transform_train,\n",
    "    )\n",
    "test_data = H5PatchDataset(\n",
    "        h5_path_x=h5_img,\n",
    "        h5_path_y=h5_label,\n",
    "        transform=transform_test,\n",
    "    )\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c3558a",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a32abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to use our custom model:\n",
    "cnn = CNN(in_channels, hidden_channels, out_features) \n",
    "\n",
    "# Uncomment to use resnet18 (pretrained model)\n",
    "# cnn = models.resnet18(weights=models.ResNet18_Weights.DEFAULT).to(device)\n",
    "# cnn.fc = nn.Linear(cnn.fc.in_features, 1)\n",
    "\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82057bc",
   "metadata": {},
   "source": [
    "## Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6f4c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    cnn.train()\n",
    "    cnn.to(device)\n",
    "\n",
    "    for i, (x_batch, y_batch) in enumerate(tqdm(train_loader, desc=\"train\", leave=False)):\n",
    "\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = cnn(x_batch)\n",
    "\n",
    "        loss = criterion(y_pred.squeeze(1), y_batch)\n",
    "        train_loss.append(loss)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_accuracy = 100*eval_accuracy(train_loader, cnn.to('cpu'))\n",
    "    test_accuracy = 100*eval_accuracy(test_loader, cnn.to('cpu'))\n",
    "\n",
    "    train_acc.append(train_accuracy)\n",
    "    test_acc.append(test_accuracy)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    print('Train accuracy: {:.00f}%'.format(train_accuracy))\n",
    "    print('Test accuracy: {:.00f}%'.format(test_accuracy))\n",
    "\n",
    "\n",
    "print(train_acc)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31268cc3",
   "metadata": {},
   "source": [
    "## Saving\n",
    "\n",
    "If you would like to save the model so that it can be loaded again later, run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aebe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"results\"\n",
    "save_path = os.path.join(output_dir, \"best.pth\")\n",
    "torch.save({\n",
    "    'model_state': cnn.state_dict(),\n",
    "    'optimizer_state': optimizer.state_dict(),\n",
    "    'epoch': epoch,\n",
    "}, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
